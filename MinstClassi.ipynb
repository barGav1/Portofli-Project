{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrudtion:Our data is the famous mnist data set,its a data set for a classification model for images of digits.\n",
    "## the data set consisits of the location of the pixel in each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading the data and seperating picture to its diffrent pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = pd.read_csv('mnist.csv', header=None)\n",
    "mnist_data.columns =[\"label\"] + [\"pixel_\" + str(i) for i in range(1, 785)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spilitting the data and creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mnist_data.iloc[:,1:]\n",
    "y=mnist_data.iloc[:,0]\n",
    "x = x.values.reshape(-1, 28, 28, 1) / 255.\n",
    "x = x.reshape(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the decision tree model\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x, y)\n",
    "\n",
    "# Learn the random forest model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x, y)\n",
    "\n",
    "# Learn the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the models and showing diffrent scoring methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree Model:\n",
      "Accuracy: 0.871 (+/- 0.004)\n",
      "Recall: 0.870 (+/- 0.004)\n",
      "Precision: 0.870 (+/- 0.004)\n",
      "F1-Score: 0.870 (+/- 0.004)\n",
      "AUC: 0.928 (+/- 0.002)\n"
     ]
    }
   ],
   "source": [
    "# Decision tree model\n",
    "dt_scores = cross_validate(dt, x, y, cv=5, scoring=['accuracy', 'recall_macro', 'precision_macro', 'f1_macro', 'roc_auc_ovr'], return_train_score=False)\n",
    "\n",
    "print(f\"Decision tree Model:\")\n",
    "print(f\"Accuracy: {np.mean(dt_scores['test_accuracy']):.3f} (+/- {np.std(dt_scores['test_accuracy']):.3f})\")\n",
    "print(f\"Recall: {np.mean(dt_scores['test_recall_macro']):.3f} (+/- {np.std(dt_scores['test_recall_macro']):.3f})\")\n",
    "print(f\"Precision: {np.mean(dt_scores['test_precision_macro']):.3f} (+/- {np.std(dt_scores['test_precision_macro']):.3f})\")\n",
    "print(f\"F1-Score: {np.mean(dt_scores['test_f1_macro']):.3f} (+/- {np.std(dt_scores['test_f1_macro']):.3f})\")\n",
    "print(f\"AUC: {np.mean(dt_scores['test_roc_auc_ovr']):.3f} (+/- {np.std(dt_scores['test_roc_auc_ovr']):.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model:\n",
      "Accuracy: 0.968 (+/- 0.002)\n",
      "Recall: 0.968 (+/- 0.002)\n",
      "Precision: 0.968 (+/- 0.002)\n",
      "F1-Score: 0.968 (+/- 0.002)\n",
      "AUC: 0.999 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "# Random forest model\n",
    "rf_scores = cross_validate(rf, x, y, cv=5, scoring=['accuracy', 'recall_macro', 'precision_macro', 'f1_macro', 'roc_auc_ovr'], return_train_score=False)\n",
    "\n",
    "print(f\"Random Forest Model:\")\n",
    "print(f\"Accuracy: {np.mean(rf_scores['test_accuracy']):.3f} (+/- {np.std(rf_scores['test_accuracy']):.3f})\")\n",
    "print(f\"Recall: {np.mean(rf_scores['test_recall_macro']):.3f} (+/- {np.std(rf_scores['test_recall_macro']):.3f})\")\n",
    "print(f\"Precision: {np.mean(rf_scores['test_precision_macro']):.3f} (+/- {np.std(rf_scores['test_precision_macro']):.3f})\")\n",
    "print(f\"F1-Score: {np.mean(rf_scores['test_f1_macro']):.3f} (+/- {np.std(rf_scores['test_f1_macro']):.3f})\")\n",
    "print(f\"AUC: {np.mean(rf_scores['test_roc_auc_ovr']):.3f} (+/- {np.std(rf_scores['test_roc_auc_ovr']):.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model:\n",
      "Accuracy: 0.922 (+/- 0.004)\n",
      "Recall: 0.921 (+/- 0.004)\n",
      "Precision: 0.921 (+/- 0.004)\n",
      "F1-Score: 0.921 (+/- 0.004)\n",
      "AUC: 0.993 (+/- 0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "lr_scores = cross_validate(lr, x, y, cv=5, scoring=['accuracy', 'recall_macro', 'precision_macro', 'f1_macro', 'roc_auc_ovr'], return_train_score=False)\n",
    "\n",
    "print(f\"Logistic Regression Model:\")\n",
    "print(f\"Accuracy: {np.mean(lr_scores['test_accuracy']):.3f} (+/- {np.std(lr_scores['test_accuracy']):.3f})\")\n",
    "print(f\"Recall: {np.mean(lr_scores['test_recall_macro']):.3f} (+/- {np.std(lr_scores['test_recall_macro']):.3f})\")\n",
    "print(f\"Precision: {np.mean(lr_scores['test_precision_macro']):.3f} (+/- {np.std(lr_scores['test_precision_macro']):.3f})\")\n",
    "print(f\"F1-Score: {np.mean(lr_scores['test_f1_macro']):.3f} (+/- {np.std(lr_scores['test_f1_macro']):.3f})\")\n",
    "print(f\"AUC: {np.mean(lr_scores['test_roc_auc_ovr']):.3f} (+/- {np.std(lr_scores['test_roc_auc_ovr']):.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating one vs one classifier and One vs rest classifiers using the native libary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-vs-one classifier for logistic regression\n",
    "lr_ovo = OneVsOneClassifier(LogisticRegression(max_iter = 1000))\n",
    "\n",
    "# Perform 5-fold cross-validation on the logistic regression model with one-vs-one classification\n",
    "# without the 'roc_auc_ovr' scoring\n",
    "lr_ovo_cv = cross_validate(lr_ovo, x, y, cv=5, scoring=['accuracy', 'recall_macro', 'precision_macro', 'f1_macro'], return_train_score=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.939 (+/- 0.009)\n",
      "Recall: 0.938 (+/- 0.009)\n",
      "precision_macro: 0.938 (+/- 0.010)\n",
      "Recall: 0.938 (+/- 0.010)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (lr_ovo_cv['test_accuracy'].mean(), lr_ovo_cv['test_accuracy'].std() * 2))\n",
    "print(\"Recall: %0.3f (+/- %0.3f)\" % (lr_ovo_cv['test_recall_macro'].mean(), lr_ovo_cv['test_recall_macro'].std() * 2))\n",
    "print(\"precision_macro: %0.3f (+/- %0.3f)\" % (lr_ovo_cv['test_precision_macro'].mean(), lr_ovo_cv['test_precision_macro'].std() * 2))\n",
    "print(\"Recall: %0.3f (+/- %0.3f)\" % (lr_ovo_cv['test_f1_macro'].mean(), lr_ovo_cv['test_f1_macro'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create one-vs-rest classifier for logistic regression\n",
    "lr_ovr = OneVsRestClassifier(LogisticRegression(max_iter = 1000))\n",
    "# Perform 5-fold cross-validation on the logistic regression model with one-vs-rest classification\n",
    "lr_ovr_cv = cross_validate(lr_ovr, x, y, cv=5, scoring=['accuracy', 'recall_macro', 'precision_macro', 'f1_macro'], return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.916 (+/- 0.009)\n",
      "Recall: 0.915 (+/- 0.009)\n",
      "precision_macro: 0.915 (+/- 0.010)\n",
      "Recall: 0.915 (+/- 0.010)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (lr_ovr_cv['test_accuracy'].mean(), lr_ovo_cv['test_accuracy'].std() * 2))\n",
    "print(\"Recall: %0.3f (+/- %0.3f)\" % (lr_ovr_cv['test_recall_macro'].mean(), lr_ovo_cv['test_recall_macro'].std() * 2))\n",
    "print(\"precision_macro: %0.3f (+/- %0.3f)\" % (lr_ovr_cv['test_precision_macro'].mean(), lr_ovo_cv['test_precision_macro'].std() * 2))\n",
    "print(\"Recall: %0.3f (+/- %0.3f)\" % (lr_ovr_cv['test_f1_macro'].mean(), lr_ovo_cv['test_f1_macro'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
